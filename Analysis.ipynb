{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import 3D plotting functionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into pandas df (dataset obtained from Kaggle)\n",
    "# https://www.kaggle.com/datasets/harrywang/wine-dataset-for-clustering\n",
    "\n",
    "data = pd.read_csv('wine-clustering.csv')\n",
    "df = data.copy() #create a copy of the dataset incase we require the original\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #no non-nulls and datatypes are all int or float\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "\n",
    "K-Means is an unsupervised learning algorithm that aims to group data based on similarity. Here's how it works:\n",
    "\n",
    "1. **Algorithm Overview**:\n",
    "   - Randomly assigns each data point to one of the K clusters.\n",
    "   - Calculates centroids for each cluster.\n",
    "   - Iteratively:\n",
    "     - Evaluates each observation, assigning it to the closest cluster based on the Euclidean distance to the centroid.\n",
    "     - Recalculates centroids when a cluster gains or loses a data point.\n",
    "     - Repeats until no further reassignments occur.\n",
    "   - The goal is to minimize the within-cluster variance (sum of squared distances from data points to their cluster centroids).\n",
    "\n",
    "2. **Strengths**:\n",
    "   - Simple and efficient.\n",
    "   - Works well when clusters are roughly spherical and well-separated.\n",
    "\n",
    "3. **Limitations**:\n",
    "   - Sensitive to initial centroid placement.\n",
    "   - Assumes equally sized and spherical clusters.\n",
    "\n",
    "4. **Applications**:\n",
    "   - Customer segmentation.\n",
    "   - Image compression.\n",
    "   - Anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any non-numeric columns (if needed)\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Standardise the features (mean - 0, std - 1)\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(numeric_df)\n",
    "\n",
    "# Choose the number of clusters (K)\n",
    "k = 2\n",
    "\n",
    "# Instantiate the K-Means class\n",
    "# init=\"random\": Initializes cluster centroids randomly.\n",
    "# n_clusters=k: Specifies the number of clusters.\n",
    "# n_init=10: Number of times K-Means will be run with different initial centroids (to avoid local minima).\n",
    "# random_state=1: Ensures reproducibility.\n",
    "kmeans = KMeans(init=\"random\", n_clusters=k, n_init=10, random_state=1)\n",
    "\n",
    "# Fit K-Means algorithm to data\n",
    "kmeans.fit(scaled_df)\n",
    "\n",
    "# View cluster assignments for each observation\n",
    "cluster_labels = kmeans.labels_\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "# Visualise the results\n",
    "# We use Principal Component Analysis (PCA) to reduce the dimensionality of the data to 2D.\n",
    "# The scatter plot shows the data points colored by their assigned clusters.\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_df = pca.fit_transform(scaled_df)\n",
    "\n",
    "plt.scatter(reduced_df[:, 0], reduced_df[:, 1], c=cluster_labels, cmap='viridis')\n",
    "plt.title(\"K-Means Clusters\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already loaded your wine dataset into the 'df' DataFrame\n",
    "\n",
    "# Remove any non-numeric columns (if needed)\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Standardise the features\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(numeric_df)\n",
    "\n",
    "# Perform PCA with 3 components\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(scaled_df)\n",
    "pca_results = pca.transform(scaled_df)\n",
    "\n",
    "# Set up a 3D plotting environment\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign PCA features to their own axes\n",
    "Xax = pca_results[:, 0]\n",
    "Yax = pca_results[:, 1]\n",
    "Zax = pca_results[:, 2]\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "ax.scatter(Xax, Yax, Zax, c=cluster_labels, cmap='viridis')\n",
    "ax.set_title(\"3D PCA Plot\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.set_zlabel(\"PC3\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_kmeans(X, k):\n",
    "    \"\"\"\n",
    "    Evaluate K-means clustering with a given K.\n",
    "\n",
    "    Args:\n",
    "        X (array-like): Input data (features).\n",
    "        k (int): Number of clusters.\n",
    "\n",
    "    Returns:\n",
    "        float: Silhouette score for the given K.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    return silhouette_avg\n",
    "\n",
    "\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for k_value in range(2, 100):\n",
    "    silhouette_score_k = evaluate_kmeans(numeric_df, k_value)\n",
    "    silhouette_scores.append({'k': k_value, 'silhouette_score': silhouette_score_k})\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "silhouettescores = pd.DataFrame(silhouette_scores)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(silhouettescores.head())\n",
    "\n",
    "# Assuming you have already computed the silhouette scores and stored them in 'silhouettescores'\n",
    "# Replace 'silhouettescores' with your actual DataFrame\n",
    "\n",
    "# Find the row with the highest silhouette score\n",
    "best_k_row = silhouettescores.loc[silhouettescores['silhouette_score'].idxmax()]\n",
    "\n",
    "# Extract the K value\n",
    "best_k = best_k_row['k']\n",
    "\n",
    "print(f\"The K value with the highest silhouette score is K={best_k}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbformat==5.10.4\n",
    "!pip install nbconvert==7.16.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
